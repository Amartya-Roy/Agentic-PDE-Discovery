# Agentic AI System for PDE Discovery

## ğŸ¯ Overview
This system uses a multi-agent AI framework (AutoGen) to automatically discover governing partial differential equations (PDEs) from spatiotemporal data. It combines Vision-Language Models (VLMs), Large Language Models (LLMs), and symbolic regression (PySINDy) in an iterative, reinforcement learning-like loop.

---

## ğŸ—ï¸ System Architecture

### **Multi-Agent Pipeline Flow**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INITIATES SYSTEM                         â”‚
â”‚              (Provides contour/surface plots)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AGENT 1: Contour_Plot_Analyser (VLM)                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”‚
â”‚  â€¢ Analyzes visual patterns in plots                             â”‚
â”‚  â€¢ Identifies: shocks, waves, dispersion, nonlinearity          â”‚
â”‚  â€¢ Outputs: Structured text description                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AGENT 2: LLM (PDE Hypothesis Generator) â­ CORE ROLE            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”‚
â”‚  ROLE: Mathematical Physicist & Pattern Interpreter              â”‚
â”‚                                                                   â”‚
â”‚  INPUT:                                                           â”‚
â”‚    - VLM's visual analysis (e.g., "high dispersion, nonlinear    â”‚
â”‚      advection, chaotic waves")                                  â”‚
â”‚    - Feedback from Critic (if iteration > 1)                     â”‚
â”‚                                                                   â”‚
â”‚  PROCESS:                                                         â”‚
â”‚    1. Maps visual cues to PDE terms:                             â”‚
â”‚       â€¢ "Dispersion" â†’ u_xxxx, u_xxx                             â”‚
â”‚       â€¢ "Nonlinear advection" â†’ u*u_x                            â”‚
â”‚       â€¢ "Diffusion" â†’ u_xx                                        â”‚
â”‚    2. Draws from knowledge base of canonical PDEs:               â”‚
â”‚       â€¢ Kuramoto-Sivashinsky: u_t = -u*u_x - u_xx - u_xxxx       â”‚
â”‚       â€¢ Burgers: u_t = -u*u_x + Î½*u_xx                           â”‚
â”‚       â€¢ KdV, Fisher-KPP, etc.                                    â”‚
â”‚    3. Generates 10 diverse candidate PDEs combining:             â”‚
â”‚       â€¢ Known PDE templates                                       â”‚
â”‚       â€¢ Novel term combinations                                   â”‚
â”‚       â€¢ Physically plausible structures                           â”‚
â”‚                                                                   â”‚
â”‚  OUTPUT: 10 equations (e.g., u_t = -u*u_x - u_xx - u_xxxx)       â”‚
â”‚                                                                   â”‚
â”‚  CONSTRAINTS:                                                     â”‚
â”‚    - Uses ONLY allowed symbols (u, u_x, u_xx, u_xxx, u_xxxx)    â”‚
â”‚    - NO code generation (purely symbolic)                         â”‚
â”‚    - Balances exploration (new terms) & exploitation (proven)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AGENT 3: Engineer (Code Generator)                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚  â€¢ Receives 10 PDEs from LLM                                     â”‚
â”‚  â€¢ Writes Python script using PySINDy:                           â”‚
â”‚    1. Loads u(x,t), x, t data                                    â”‚
â”‚    2. Computes derivatives (u_t, u_x, u_xx, u_xxx, u_xxxx)      â”‚
â”‚    3. For each PDE:                                              â”‚
â”‚       - Fits coefficients via least-squares                      â”‚
â”‚       - Calculates Relative L2 Error                             â”‚
â”‚    4. Saves results to CSV (scores, errors, boundaries)          â”‚
â”‚  â€¢ Output: Executable Python code + fitted PDEs with scores      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AGENT 4: Executor (Code Runner)                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚  â€¢ Runs Engineer's code locally (no Docker)                      â”‚
â”‚  â€¢ Returns: Exit code, output, errors                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AGENT 5: Scientist (Quality Control)                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚  â€¢ Checks execution success (exitcode: 0)                        â”‚
â”‚  â€¢ Validates outputs:                                             â”‚
â”‚    - Files exist (score.csv, error.csv, etc.)                    â”‚
â”‚    - Scores are numerical                                         â”‚
â”‚  â€¢ Reviews physical plausibility:                                 â”‚
â”‚    - Do terms make sense? (e.g., u_xxxx for dispersion)          â”‚
â”‚    - Are coefficients reasonable?                                 â”‚
â”‚  â€¢ Signals: ROGER CRITIC (pass) or ROGER ENGINEER (fix code)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AGENT 6: Critic (Decision Maker) ğŸ“ GATEKEEPER                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚  ROLE: Final arbiter of truth                                    â”‚
â”‚                                                                   â”‚
â”‚  EVALUATES:                                                       â”‚
â”‚    1. All 10 fitted PDEs (not just best score)                   â”‚
â”‚    2. Mathematical validity (well-posed, consistent)             â”‚
â”‚    3. Physical plausibility (terms represent real processes)     â”‚
â”‚    4. Fit quality (L2 error, boundary behavior)                  â”‚
â”‚                                                                   â”‚
â”‚  DECISION LOGIC:                                                  â”‚
â”‚    IF any PDE meets ALL criteria:                                â”‚
â”‚       â€¢ L2 Error â‰¤ 0.01                                          â”‚
â”‚       â€¢ Mathematically sound                                      â”‚
â”‚       â€¢ Physically meaningful                                     â”‚
â”‚       â€¢ Stable boundaries                                         â”‚
â”‚    THEN:                                                          â”‚
â”‚       â†’ Signal TERMINATE (success!)                              â”‚
â”‚    ELSE:                                                          â”‚
â”‚       â†’ Analyze failures (e.g., "missing dispersion term")       â”‚
â”‚       â†’ Generate specific feedback for LLM                        â”‚
â”‚       â†’ Signal ROGER LLM (iterate)                               â”‚
â”‚                                                                   â”‚
â”‚  FEEDBACK EXAMPLES:                                               â”‚
â”‚    - "High errors suggest missing u_xxxx for dispersion"         â”‚
â”‚    - "Coefficient on u*u_x too large; reduce nonlinearity"       â”‚
â”‚    - "Add damping term u_xx to stabilize"                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                       â”‚
                â–¼                       â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  TERMINATE    â”‚      â”‚  BACK TO LLM â”‚
        â”‚  (Success!)   â”‚      â”‚  (Iterate)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  LLM Receives Critic Feedback          â”‚
            â”‚  - Incorporates suggestions            â”‚
            â”‚  - Generates 10 NEW PDEs               â”‚
            â”‚  - Cycle repeats (max 100 rounds)     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  The LLM's Role in Detail

### **Why Do We Need an LLM for PDE Discovery?**

Traditional symbolic regression (e.g., genetic programming, LASSO) explores term combinations blindly. **The LLM brings domain knowledge** to guide the search:

1. **Physical Intuition**: Knows that:
   - Burgers equation has `u*u_x` (shock formation)
   - KS equation needs `u_xxxx` (dispersion stabilization)
   - Diffusion requires `u_xx` (smoothing)

2. **Pattern Recognition**: Maps visual cues â†’ math:
   - VLM says "chaotic waves" â†’ LLM proposes `-u*u_x - u_xxxx`
   - VLM says "smooth diffusion" â†’ LLM proposes `Î½*u_xx`

3. **Iterative Learning**: Unlike static methods, the LLM:
   - Receives feedback ("error too high, add u_xxxx")
   - Adjusts next generation of PDEs
   - Converges faster than blind search

### **What the LLM Does NOT Do**
- âŒ Does NOT run simulations
- âŒ Does NOT compute derivatives
- âŒ Does NOT fit coefficients
- âœ… ONLY generates symbolic PDE forms (e.g., `u_t = term1 + term2`)

---

## ğŸ“Š Scoring System

### Relative L2 Error Metric
```python
error = ||u_t_true - u_t_predicted|| / ||u_t_true||
```

| Error Range | Interpretation | Action |
|-------------|----------------|--------|
| < 0.01 | âœ… Excellent | Accept if physically valid |
| 0.01â€“0.03 | ğŸŸ¡ Good | Review carefully |
| 0.03â€“0.05 | ğŸŸ  Acceptable | Likely needs refinement |
| > 0.05 | ğŸ”´ Poor | Reject, iterate |

---

## ğŸš€ How to Speed Up Execution

### Current Bottlenecks
1. **API Latency**: Each agent call to NVIDIA API takes 5-15s
2. **Large Data**: 1024Ã—251 grid requires heavy computation
3. **Many Iterations**: Can take 10+ cycles to converge

### Speed Optimization Strategies

#### 1. **Use Local LLMs (10x faster)**
```python
# Replace NVIDIA API with local Ollama/LM Studio
llm_config = {
    "config_list": [{
        "model": "llama3.1:70b",  # Run locally
        "base_url": "http://localhost:11434/v1",
        "api_key": "not-needed"
    }],
    "cache_seed": None  # Disable caching for faster response
}
```

#### 2. **Reduce Data Resolution**
```python
# Faster: 256Ã—128 instead of 1024Ã—251
subsample_prompt_text, u_full, x_full, t_full = load_pde_data_and_subsample(
    'KS', 
    n_x_sub=256,  # Was 1024
    n_t_sub=128   # Was 251
)
```

#### 3. **Parallelize Agent Calls**
```python
# Use async execution for non-dependent agents
llm_config["timeout"] = 60  # Fail fast
```

#### 4. **Reduce Max Rounds**
```python
groupchat = autogen.GroupChat(
    agents=[...],
    max_round=20,  # Was 100 - stop sooner
)
```

#### 5. **Cache VLM Analysis**
```python
# Run VLM once, reuse description across iterations
vlm_description = Contour_Plot_Analyser.generate_reply(messages=[seed])
# Store and reuse instead of calling repeatedly
```

### **Recommended Fast Configuration**
```python
FAST_CONFIG = {
    "data_resolution": (256, 128),
    "max_rounds": 20,
    "use_local_llm": True,
    "cache_vlm": True,
    "timeout": 30
}
```
**Expected speedup: 5-10x faster** (from 2 hours â†’ 15-20 mins)

---

## ğŸ¯ Improving Accuracy

### Current Accuracy Issues
1. **LLM Hallucination**: Generates plausible but wrong PDEs
2. **Coefficient Mismatch**: Correct structure, wrong signs
3. **Premature Termination**: Accepts suboptimal PDEs

### Accuracy Improvements

#### 1. **Strengthen LLM Prompt**
```python
# Add explicit PDE examples to prompt
llm_prompt += """
KNOWN REFERENCE PDEs:
- Kuramoto-Sivashinsky: u_t = -u*u_x - u_xx - u_xxxx
- Burgers: u_t = -u*u_x + 0.1*u_xx
- KdV: u_t = -6*u*u_x - u_xxx

Match these patterns when visual cues align.
"""
```

#### 2. **Improve Critic Thresholds**
```python
# Stricter acceptance criteria
if score <= 0.005 and physically_valid and boundaries_stable:  # Was 0.01
    terminate()
```

#### 3. **Add Ground Truth Hints**
```python
# For known datasets, provide hints
if dataset == 'KS':
    llm_prompt += "Expect: nonlinear advection + diffusion + dispersion"
```

#### 4. **Multi-Metric Evaluation**
```python
# Don't rely only on L2 error
scores = {
    "l2_error": relative_l2_error(u_t_true, u_t_pred),
    "coefficient_stability": check_coefficient_magnitude(),
    "boundary_error": compute_boundary_mismatch(),
    "physical_validity": check_term_plausibility()
}
```

#### 5. **Ensemble Approach**
```python
# Run system 3-5 times, pick consensus PDE
results = [run_discovery() for _ in range(5)]
best_pde = vote_best_pde(results)
```

---

## ğŸ“ File Structure

```
pdefinder/
â”œâ”€â”€ llm4ed_agentic_ai_new_vlm_v1.ipynb  # Main notebook
â”œâ”€â”€ Bayesian_PDE_Discovery_DATA/         # Data files
â”‚   â””â”€â”€ kuramoto_sivishinky.mat
â”œâ”€â”€ surface_contour_plots/               # Visualization inputs
â”‚   â”œâ”€â”€ KS_contour_896.png
â”‚   â””â”€â”€ KS_surface_896.png
â”œâ”€â”€ u.npy, x.npy, t.npy                 # Loaded data arrays
â”œâ”€â”€ score.csv                            # PDE scores (output)
â”œâ”€â”€ error.csv                            # Error fields (output)
â””â”€â”€ pde_sim.py                           # Last executed code
```

---

## ğŸ”¬ Example Run

### Input
- **Dataset**: Kuramoto-Sivashinsky (KS)
- **True PDE**: `u_t = -u*u_x - u_xx - u_xxxx`

### Iteration 1
- **VLM**: "Chaotic waves, dispersion, nonlinear advection"
- **LLM**: Generates 10 PDEs including `u_t = -u*u_x - u_xx - u_xxxx`
- **Engineer**: Fits coefficients, computes L2 = 0.008
- **Scientist**: Validates output
- **Critic**: Checks all PDEs, finds #3 has L2=0.008, physically valid â†’ **TERMINATES**

### Output
```
âœ… DISCOVERED PDE:
u_t = -1.0021*u*u_x - 0.9987*u_xx - 1.0003*u_xxxx
L2 Error: 0.0084
Status: ACCEPTED
```

---

## ğŸ› ï¸ Troubleshooting

### Problem: Hallucination (Wrong PDE Selected)
**Solution**: 
- Increase data resolution
- Add PDE examples to LLM prompt
- Use stricter L2 threshold (< 0.005)

### Problem: Slow Execution (Hours)
**Solution**:
- Use local LLM (Ollama)
- Reduce data to 256Ã—128
- Lower max_rounds to 20
- Cache VLM analysis

### Problem: Code Execution Errors
**Solution**:
- Check `use_docker: False` in executor
- Ensure PySINDy installed: `pip install pysindy`
- Verify data files exist in `Bayesian_PDE_Discovery_DATA/`

---

## ğŸ“š Key References

1. **SINDy**: Brunton et al. (2016) - Sparse Identification of Nonlinear Dynamics
2. **AutoGen**: Microsoft Research - Multi-agent conversation framework
3. **Kuramoto-Sivashinsky Equation**: Canonical chaotic PDE

---

## ğŸ“ Educational Summary

**What makes this system "agentic"?**
- Agents have specialized roles (VLMâ†’LLMâ†’Engineerâ†’Scientistâ†’Critic)
- Feedback loops enable learning (Critic guides LLM)
- Autonomous decision-making (Critic decides when to stop)

**Why is the LLM critical?**
- Bridges vision (plots) and math (PDEs)
- Incorporates centuries of physics knowledge
- Adapts based on feedback (pseudo-RL)

**When should you use this?**
- Unknown PDEs from experimental data
- Automated scientific discovery
- Rapid hypothesis testing (10 PDEs per iteration)

---

## ğŸ“ Quick Start

```bash
# 1. Install dependencies
pip install autogen-agentchat pysindy scipy numpy

# 2. Set API key in notebook
api_key = "your-nvidia-api-key"

# 3. Run all cells sequentially

# 4. Monitor output for:
#    - VLM analysis
#    - 10 generated PDEs
#    - Fitted coefficients + scores
#    - TERMINATE signal (success!)
```

---

**Author**: Amartya Roy  
**Version**: 2.0 (Optimized)  
**Last Updated**: October 2025
